{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import xmltodict\n",
    "import json\n",
    "import mne\n",
    "import matplotlib\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up paths for inputs and outputs\n",
    "input_path = './input_txt/'\n",
    "output_path_edf = './output_edf/'\n",
    "output_path_fif = './output_fif/'\n",
    "\n",
    "ch_one = '2019-12-17_123934_RawData_Ch1.txt'\n",
    "ch_two = '2019-12-17_123934_RawData_Ch2.txt'\n",
    "xml = '2019-12-17_123934.xml'\n",
    "out_name = '2019-12-17_123934.edf'\n",
    "\n",
    "ch_one_path = input_path + ch_one\n",
    "ch_two_path = input_path + ch_two\n",
    "xml_path = input_path + xml\n",
    "out_file_path_edf = output_path_edf + out_name\n",
    "out_file_path_fif = output_path_fif + out_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from .txt and convert data into numpy array\n",
    "#each dataset is composed of two channels (.txt) and one information doc (.xml)\n",
    "raw_one = []\n",
    "raw_two = []\n",
    "\n",
    "with open(ch_one_path) as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        raw_one.append(float(line.strip()))\n",
    "        line = f.readline()\n",
    "f.close()\n",
    "\n",
    "with open(ch_two_path) as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        raw_two.append(float(line.strip()))\n",
    "        line = f.readline()\n",
    "f.close()\n",
    "\n",
    "signal = [np.array(raw_one, dtype=np.float32), np.array(raw_two, dtype=np.float32)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read .xml doc and extract needed info\n",
    "fileptr = open(xml_path, \"r\")\n",
    "\n",
    "xml_content = fileptr.read()\n",
    "\n",
    "my_ordered_dict = xmltodict.parse(xml_content)\n",
    "dict = json.loads(json.dumps(my_ordered_dict))\n",
    "\n",
    "sample_rate = eval(dict['RECORD_INFO']['Record']['SamplesFreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output_edf/2019-12-17_123934.edf\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#setting up info needed for .edf generation and write .edf file\n",
    "headers = [{'label':'ch1', \n",
    "            'dimension': 'uV',\n",
    "            'sample_rate': sample_rate,\n",
    "            'physical_max': 5000,\n",
    "            \"physical_min\": -5000,\n",
    "            'digital_max': 5000,\n",
    "            'digital_min': -5000,\n",
    "            'transducer': 'None',\n",
    "            'prefilter': 'None'},\n",
    "            {'label':'ch2', \n",
    "            'dimension': 'uV',\n",
    "            'sample_rate': sample_rate,\n",
    "            'physical_max': 5000,\n",
    "            \"physical_min\": -5000,\n",
    "            'digital_max': 5000,\n",
    "            'digital_min': -5000,\n",
    "            'transducer': 'None',\n",
    "            'prefilter': 'None'}]\n",
    "with open(out_file_path_edf, 'w') as output:\n",
    "    print(out_file_path_edf)\n",
    "    flag = pyedflib.highlevel.write_edf(output.name, signal, headers, header=None, digital=False, file_type=-1, block_size=1)\n",
    "    print(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\admin\\Desktop\\work\\my_evaluator\\output_edf\\2019-12-17_123934.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "#read the newly created .edf using mne\n",
    "raw=mne.io.read_raw_edf(out_file_path_edf,preload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>July 06, 2021  16:15:25 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 2 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1998.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>999.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>2019-12-17_123934.edf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>01:04:36 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawEDF | 2019-12-17_123934.edf, 2 x 7746246 (3877.0 s), ~7 kB, data not loaded>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "1938 matching events found\n",
      "Setting baseline interval to [-0.2002002002002002, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 1938 events and 1400 original time points ...\n",
      "1 bad epochs dropped\n",
      "Loading data for 1937 events and 1400 original time points ...\n",
      "Loading data for 20 events and 1400 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1919x1016 with 4 Axes>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 20 events and 1400 original time points ...\n",
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "#create events using mne\n",
    "#events are equally spaced out for epoch division\n",
    "new_events = mne.make_fixed_length_events(raw, duration=2.)\n",
    "event_dict = {'divide':1}\n",
    "epochs = mne.Epochs(raw,new_events)\n",
    "epochs.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1 events and 1400 original time points ...\n",
      "Loading data for 1 events and 1400 original time points ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1919x1016 with 4 Axes>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: none\n"
     ]
    }
   ],
   "source": [
    "epochs[2].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
